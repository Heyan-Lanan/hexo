---
title: 并行计算在雷达信号处理中的应用
date: 2022-3-3 22:38:00
comment: 'waline'
categories:  并行计算
tags:  并行计算
index_img: /img/头像.jpg
---

<center><b><font size = 5> 并行计算在雷达信号处理中的应用</font></b></center> 

<br>

<center><font size = 3>   PB9030888 张舒恒</font></center>                                                                                 



#### 1.问题背景

​	现代雷达面临着难以捕捉目标和工作环境复杂等多种问题。不论从研发角度还是从用户需求角度都对雷达系统提出了越来越高的要求，雷达技术必须与时俱进。

​	传统雷达信号处理技术使用可编程门阵列(FPGA)和数字信号处理器(DSP)，其计算速度虽然能够满足要求，但FPGA和DSP的软件程序复用性较低，程序调试困难。而仅使用CPU作为计算核心的信号处理机，受限于CPU时钟频率和内核数目，在处理实时数据时面临着系统资源消耗过多、性能下降等问题。

​	为了进一步提升雷达系统计算能力，现在使用图形处理器(GPU)代替DSP和FPGA作为雷达的计算核心，组成GPU+CPU的异构平台作为新型的雷达信号处理系统架构。GPU内含并行计算设备体系结构，开发人员可使用C语言对GPU进行编程。

#### 2.GPU并行计算关键技术

​	对GPU中串行程序并行化的方法有两种：(1)对一个完整的项目程序进行并行加速，将所有计算步骤放在GPU完成；(2)将项目程序中包含大量的计算密集型算法提取出来，单独导入GPU进行计算。

##### 		2.1共享内存访问冲突与避免

​	共享内存是位于GPU流处理器中的低延迟内存池，该内存池被线程块中的所有线程所共享。在调用共享内存时，线程会通过32个存储体进行访问。当线程束中的多个线程在同一存储体中访问不同地址数据时会发生冲突，这会造成访存阻塞，降低计算性能并影响带宽利用率。解决这种存储体冲突的方法是在每N个元素之后添加一个字(N是存储体数量)。由于对内存数据进行了填充，之前属于同一个存储体的存储单元现在被传播到了不同的存储体中，改变了从字到存储体的映射。

##### 		2.2全局内存的对齐与合并

​	全局内存是GPU中存储空间最大、使用频率最多的内存。一般来说，数据传输过程中内存请求越多，未被使用的字节被传回的可能性就越高，会导致数据吞吐量降低。所有的全局内存访问都会通过二级缓存(32Byte内存)，当设备的内存首地址是32Byte的偶数倍时，就可实现对齐内存访问。在一个线程束中所有32个线程访问一个地址连续的内存块时就能实现合并访问。因此可将全局内存中的数据大小尽量整合成32Byte的整数倍以增加数据对齐的灵活性，从而提高并行计算效率。

#### 3.GPU并行计算实现效果

​	将GPU处理结果与传统的FPGA和DSP处理结果进行对比。脉冲压缩、动目标检测和杂波图误差在10^-4级别，恒虚警检测器CFAR输出结果完全一致。对于脉冲压缩，动目标检测和恒虚警检测，在并行GPU和传统FPGA+DSP的处理时间对比如下表所示。

| 处理过程        | FPGA+DSP(ms) | GPU并行(ms) | 加速比 |
| :----------: | :---: | :---: | :---: |
| 脉冲压缩(FFT法) | 10.5646 | 0.3864 | 27.34 |
| 动目标检测(FFT法) | 9.4601 | 0.2213 | 42.75 |
| 动目标检测(FIR法) | 42.4897 | 0.0473 | 898.30 |
| 恒虚警检测 | 0.8154 | 0.1221 | 6.68 |

​	可以看出，在包含大量FFT和点乘运算的脉冲压缩和动目标检测部分GPU并行计算加速效果明显。对于矩阵相乘运算，GPU表现出惊人的加速效果，在极短时间内实现了基于时域有限脉冲响应滤波器的MTD。在存在大量逻辑运算的恒虚警检测部分，经过GPU的并行内存优化之后性能也得到了较大提升，但与脉冲压缩和动目标检测相比，加速的幅度较小，仍需要找到更好的优化方法。

#### 4.拓展性的研究与讨论

​		由于GPU内含统一计算设备体系结构(Compute Unified Device Architecture)，所以在CUDA下开发的软件具有很强的可移植性，可满足所有计算能力在GPU上直接运行。

​		另外，相较于FPGA动辄十几分钟甚至一个小时的烧写时间，GPU软件编译仅需几秒，程序调试几乎支持所有的C/C++集成开发环境，摆脱了仿真器束缚，大大增加了灵活性与拓展性。目前市场上的计算级GPU以英伟达公司的产品为主，CUDA驱动的向下兼容和向上兼容都较稳定，使CUDA程序具有很好的可移植性，避免再次开发相似功能，节省了人力资源，降低了开发难度，提高了开发效率。在面对更大计算需求时可以灵活扩展或升级GPU。

#### 5.设备采购

|                         设备                          | 数量 | 价格(万元) |
| :---------------------------------------------------: | :--: | :--------: |
|                  ISAR实时信号处理机                   |  1   |     56     |
| 基于6U VPX的 XC7VX690T+C6678的双FMC接口雷达通信处理板 |  1   |     17     |
|                  NVIDIA Tesla P6 GPU                  |  2   |     7      |
|         AMD Ryzen ThreadRipper Pro 3995WX CPU         |  1   |     4      |



#### 参考文献

[1]DING L L,LI L Y.Research on radar software architectur based software bus technology[J].Information Technology and Informatization,2017,33(7):103-105.丁琳琳，李路野.可重构雷达架构研究[J].信息技术与信息化，2017,33(7):103-105.

[2]YU W W.Research on the parallel processing technology of multimode radar signal processing algorithm based on GPU[D].Beijing:Beijing Institute of Technology,2016.于婉婉.基于GPU的多模式基于GPU的多模式雷达信号处理算法并行实现技术研究[D].北京：北京理工大学，2016.

[3]TANG M W.GPU Acceleration of 1D3V particle-in-cell simulation software BUMBLEBEE[D].Chengdu:University of Electronic Science and Technology of China,2016.唐茂文.1D3V粒子模拟软件BUMBLEBEE的GPU并行研究[D].成都：电子科技大学，2016.

[4]SHANECOOK.CUDA parallel computing design GPU programming guide[M].Beijing:Machinery Industry Press,2014.SHANECOOK.CUDA并行计算设计GPU编程指南[M].北京：机械工业出版社，2014.